# LoRA(Low-Rank Adaptation of Large Language Models)
> 큰 인공지능 모델을 전체 수정하지 않음.
> 작은 '추가 모듈'만 학습해서 효율적으로 성능을 향상시키는 방법

- 기존 가중치는 고정
- 저랭크 행렬 (A, B)만 학습
- 빠르고 가볍고 안정적인 미세조정 기법
  
---

## 2. 왜 쓰나요?
| 일반 파인튜닝 | LoRA |
|---------------|------|
| 전체 모델 수정 | 작은 모듈만 수정 |
| 메모리 많이 사용 | 메모리 절약 |
| 느림 | 빠름 |
| 배포 불편 | LoRA 모듈만 배포 가능 |

---
