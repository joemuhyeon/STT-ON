# 🧠 LoRA(Low-Rank Adaptation of Large Language Models)
> 큰 인공지능 모델을 전체 수정하지 않음.
> 작은 '추가 모듈'만 학습해서 효율적으로 성능을 향상시키는 방법

- 기존 가중치는 고정
- 저랭크 행렬 (A, B)만 학습
- 빠르고 가볍고 안정적인 미세조정 기법
  
---

## 🤔 왜 쓰나요?
| 일반 파인튜닝 😓 | LoRA 😊 |
|------------------|---------|
| 모델 전체 수정 🔧 | 작은 조각만 수정 🧩 |
| GPU 메모리 많이 먹음 💥 | 메모리 절약 💾 |
| 느림 🐢 | 빠름 ⚡ |
| 파일 크기 큼 📦 | 가벼움 ✨ |

🔥 LoRA는 똑똑한 AI를 더 가볍고 빠르게 만드는 비법!
---
y = W * x ← W는 무거운 가중치

근데 LoRA는 `W`를 직접 안 바꿔요.  
대신 `A`랑 `B`라는 **작은 조각**만 학습해서 이렇게 덧붙여요:
