## 🎯 음성 인식 성능 평가 지표: WER & CER

ASR(자동 음성 인식) 모델의 성능을 측정할 때 가장 많이 사용하는 두 가지 지표는 **WER (Word Error Rate)** 와 **CER (Character Error Rate)** 입니다.

---

### 🔤 Word Error Rate (WER)

> 단어 단위의 오류율을 측정합니다.  
> **영어**처럼 단어 경계가 뚜렷한 언어에 적합합니다.

#### 계산식:
WER = (S + D + I) / N 
- **S (Substitution)**: 잘못 인식된 단어 수  
- **D (Deletion)**: 빠진 단어 수  
- **I (Insertion)**: 추가된 단어 수  
- **N**: 정답 문장의 총 단어 수
#### 예시:
참조 문장: 나는 학교에 간다 <br>
예측 문장: 나는 공원에 갔다 <br><br>
| 항목          | 값                 |
| ----------- | ----------------- |
| 기준 문장       | 나는 학교에 간다 |
| 단어 수 (어절 수) | 3개 |
| 오류 개수 (대체)  | 2개 |
| **WER**     | 2 / 3 = **66.7%** |

S = 2 (학교 → 공원, 간다 → 갔다) <br>
WER = (2) / 3 = 0.5 → 50% <br>
- 띄어쓰기 기준 어절이 단어 단위입니다.
- 형태소 기준이나 의미 기준으로 쪼개면 계산 기준이 달라져 혼란 생김
---

### 🔡 Character Error Rate (CER)

> 문자 단위의 오류율을 측정합니다.  
> **한국어, 일본어, 중국어** 등 단어 경계가 애매한 언어에 적합합니다.

## 📌 CER은 이런 상황에 유용합니다
- 한국어처럼 띄어쓰기가 모호한 경우 (예: “학교 에” vs “학교에”)
- 글자 수준의 실수 감지를 원할 때
- 단어 전체는 다르지만 발음이나 모양이 비슷한 경우, CER이 WER보다 더 세밀하게 잡아냄
  
#### 계산식:
CER = (S + D + I) / N

- 계산 방식은 WER과 같지만 **단위가 문자**입니다.

#### 예시:
참조 문장: 나는학교에간다  
예측 문장: 나는공원에갔다
-(띄어쓰기 없이 계산하는 것이 일반적이며, CER에서는 공백도 문자로 셀 수 있지만 한국어에서는 보통 제외하는 경우가 많습니다.)

### 🧩 1. 문자 단위 비교
| 인덱스 | 참조 문자 | 예측 문자 | 오류 유형 |
| --- | ----- | ----- | ----- |
| 1   | 나     | 나     | ✅ 일치  |
| 2   | 는     | 는     | ✅ 일치  |
| 3   | 학     | 공     | ❌ 대체  |
| 4   | 교     | 원     | ❌ 대체  |
| 5   | 에     | 에     | ✅ 일치  |
| 6   | 간     | 갔     | ❌ 대체  |
| 7   | 다     | 다     | ✅ 일치  |
### 🧮 2. CER 계산
S (Substitution) = 3 (학→공, 교→원, 간→갔)
- **S (Substitution)**: 잘못 인식된 단어 수  
D (Deletion) = 0
- **D (Deletion)**: 빠진 단어 수
I (Insertion) = 0
- **I (Insertion)**: 추가된 단어 수
N (참조 문자의 총 개수) = 7

CER = (3)/ 7 = 42.86%




