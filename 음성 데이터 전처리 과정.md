# 🔁 음성 데이터 전처리 과정 (Preprocessing Pipeline)

---
ASR(자동 음성 인식) 모델의 성능을 극대화 하기 위해서는 **`고품질의 전처리 과정`** 이 필수입니다.
이 과정은 음성 파일을 모델이 학습 가능한 형태로 정제·변환하는 작업입니다.

---

## 🧱 1. 형식 정리 및 리샘플링 (Resampling)
- 다양한 형식(mp3, wav, m4a 등)을 **표준 형식**으로 통일
- 일반적으로 **16kHz, mono 채널, .wav 형식**이 기준
- 'ffmpeg', 'torchaudio', 'sox' 등을 사용

###  🔧 예시 (ffmpeg)
```bash
ffmpeg -i input.mp3 -ar 16000 -ac 1 output.wav
```
---

## 🔇 2. 무음 제거 (Silence Trimming)
- 앞/뒤/중간의 긴 무음 구간 제거
- 학습 데이터의 효율성과 정확도 향상
- **VAD(Voice Activity Detection)** 또는 단순 energy threshold 기반 <br>
🔧 예시 (torchaudio)
```python
import torchaudio
waveform, sr = torchaudio.load("audio.wav")
trimmed = torchaudio.functional.vad(waveform, sample_rate=sr)
```
---

## 🔊 3. 볼륨 정규화 (Volume Normalization)
- 각 오디오 간의 불륨 차이 보정
- 전체 음성의 **신호 강도(Signal Amplitude)**를 비슷하게 맞춤 <br>
🔧 예시
```python
normalized = waveform / waveform.abs().max()
```
---

## ✂️ 4. 클립 분할 (Segmentation)
- 긴 음성 파일을 문장 단위로 분할
- 자막 또는 주석 파일(JSON, TSV 등)을 활용 <br>
🔧 예시 (자막 JSON 기반)
```json
{
  "segments": [
    { "start": 0.0, "end": 3.5, "text": "안녕하세요." },
    { "start": 3.5, "end": 7.0, "text": "오늘은 날씨가 좋습니다." }
  ]
}
```
---

## 🎵 5. 특징 추출 (Feature Extraction)
모델에 입력할 스펙트로그램 특징 벡터로 변환합니다.
| 유형            | 설명                     |
| ------------- | ---------------------- |
| **MFCC**      | 전통적인 음성 인식 특징          |
| **Mel Spec.** | 인간 청각 기반의 주파수 변환       |
| **Log-Mel**   | Whisper 등에서 사용하는 표준 포맷 |

🔧 예시 (torchaudio)
```python
import torchaudio.transforms as T

mel_transform = T.MelSpectrogram(sample_rate=16000, n_mels=80)
mel = mel_transform(waveform)
```
🔧 예시 (Whisper 전용)
```python
import whisper

audio = whisper.load_audio("clip.wav")
mel = whisper.log_mel_spectrogram(audio)
```
---

## 🧽 6. 텍스트 정제 (Text Normalization)
- 학습 레이블이 되는 텍스트를 모델 친화적으로 정제
- 숫자 -> 한글화, 특수문자 제거, 소문자화, 불필요한 공백 제거 등

🔧 예시
```python
import re

def clean_text(text):
    text = re.sub(r"[^가-힣0-9\s]", "", text)
    text = text.replace("123", "일이삼")  # 예시
    return text.strip()
```
---

## 📦 7. 병렬 전처리 예시 (HuggingFace datasets + map)
```python
from datasets import load_dataset

dataset = load_dataset("csv", data_files="meta.csv")

def preprocess(example):
    audio = whisper.load_audio(example["path"])
    mel = whisper.log_mel_spectrogram(audio)
    text = clean_text(example["text"])
    return {"input_features": mel, "labels": text}

dataset = dataset.map(preprocess)
```
---














