# ğŸ” ìŒì„± ë°ì´í„° ì „ì²˜ë¦¬ ê³¼ì • (Preprocessing Pipeline)

---
ASR(ìë™ ìŒì„± ì¸ì‹) ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ê·¹ëŒ€í™” í•˜ê¸° ìœ„í•´ì„œëŠ” **`ê³ í’ˆì§ˆì˜ ì „ì²˜ë¦¬ ê³¼ì •`** ì´ í•„ìˆ˜ì…ë‹ˆë‹¤.
ì´ ê³¼ì •ì€ ìŒì„± íŒŒì¼ì„ ëª¨ë¸ì´ í•™ìŠµ ê°€ëŠ¥í•œ í˜•íƒœë¡œ ì •ì œÂ·ë³€í™˜í•˜ëŠ” ì‘ì—…ì…ë‹ˆë‹¤.

---

## ğŸ§± 1. í˜•ì‹ ì •ë¦¬ ë° ë¦¬ìƒ˜í”Œë§ (Resampling)
- ë‹¤ì–‘í•œ í˜•ì‹(mp3, wav, m4a ë“±)ì„ **í‘œì¤€ í˜•ì‹**ìœ¼ë¡œ í†µì¼
- ì¼ë°˜ì ìœ¼ë¡œ **16kHz, mono ì±„ë„, .wav í˜•ì‹**ì´ ê¸°ì¤€
- 'ffmpeg', 'torchaudio', 'sox' ë“±ì„ ì‚¬ìš©

###  ğŸ”§ ì˜ˆì‹œ (ffmpeg)
```bash
ffmpeg -i input.mp3 -ar 16000 -ac 1 output.wav
```
---

## ğŸ”‡ 2. ë¬´ìŒ ì œê±° (Silence Trimming)
- ì•/ë’¤/ì¤‘ê°„ì˜ ê¸´ ë¬´ìŒ êµ¬ê°„ ì œê±°
- í•™ìŠµ ë°ì´í„°ì˜ íš¨ìœ¨ì„±ê³¼ ì •í™•ë„ í–¥ìƒ
- **VAD(Voice Activity Detection)** ë˜ëŠ” ë‹¨ìˆœ energy threshold ê¸°ë°˜ <br>
ğŸ”§ ì˜ˆì‹œ (torchaudio)
```python
import torchaudio
waveform, sr = torchaudio.load("audio.wav")
trimmed = torchaudio.functional.vad(waveform, sample_rate=sr)
```
---

## ğŸ”Š 3. ë³¼ë¥¨ ì •ê·œí™” (Volume Normalization)
- ê° ì˜¤ë””ì˜¤ ê°„ì˜ ë¶ˆë¥¨ ì°¨ì´ ë³´ì •
- ì „ì²´ ìŒì„±ì˜ **ì‹ í˜¸ ê°•ë„(Signal Amplitude)**ë¥¼ ë¹„ìŠ·í•˜ê²Œ ë§ì¶¤ <br>
ğŸ”§ ì˜ˆì‹œ
```python
normalized = waveform / waveform.abs().max()
```
---

## âœ‚ï¸ 4. í´ë¦½ ë¶„í•  (Segmentation)
- ê¸´ ìŒì„± íŒŒì¼ì„ ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„í• 
- ìë§‰ ë˜ëŠ” ì£¼ì„ íŒŒì¼(JSON, TSV ë“±)ì„ í™œìš© <br>
ğŸ”§ ì˜ˆì‹œ (ìë§‰ JSON ê¸°ë°˜)
```json
{
  "segments": [
    { "start": 0.0, "end": 3.5, "text": "ì•ˆë…•í•˜ì„¸ìš”." },
    { "start": 3.5, "end": 7.0, "text": "ì˜¤ëŠ˜ì€ ë‚ ì”¨ê°€ ì¢‹ìŠµë‹ˆë‹¤." }
  ]
}
```
---

## ğŸµ 5. íŠ¹ì§• ì¶”ì¶œ (Feature Extraction)
ëª¨ë¸ì— ì…ë ¥í•  ìŠ¤í™íŠ¸ë¡œê·¸ë¨ íŠ¹ì§• ë²¡í„°ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
| ìœ í˜•            | ì„¤ëª…                     |
| ------------- | ---------------------- |
| **MFCC**      | ì „í†µì ì¸ ìŒì„± ì¸ì‹ íŠ¹ì§•          |
| **Mel Spec.** | ì¸ê°„ ì²­ê° ê¸°ë°˜ì˜ ì£¼íŒŒìˆ˜ ë³€í™˜       |
| **Log-Mel**   | Whisper ë“±ì—ì„œ ì‚¬ìš©í•˜ëŠ” í‘œì¤€ í¬ë§· |

ğŸ”§ ì˜ˆì‹œ (torchaudio)
```python
import torchaudio.transforms as T

mel_transform = T.MelSpectrogram(sample_rate=16000, n_mels=80)
mel = mel_transform(waveform)
```
ğŸ”§ ì˜ˆì‹œ (Whisper ì „ìš©)
```python
import whisper

audio = whisper.load_audio("clip.wav")
mel = whisper.log_mel_spectrogram(audio)
```
---

## ğŸ§½ 6. í…ìŠ¤íŠ¸ ì •ì œ (Text Normalization)
- í•™ìŠµ ë ˆì´ë¸”ì´ ë˜ëŠ” í…ìŠ¤íŠ¸ë¥¼ ëª¨ë¸ ì¹œí™”ì ìœ¼ë¡œ ì •ì œ
- ìˆ«ì -> í•œê¸€í™”, íŠ¹ìˆ˜ë¬¸ì ì œê±°, ì†Œë¬¸ìí™”, ë¶ˆí•„ìš”í•œ ê³µë°± ì œê±° ë“±

ğŸ”§ ì˜ˆì‹œ
```python
import re

def clean_text(text):
    text = re.sub(r"[^ê°€-í£0-9\s]", "", text)
    text = text.replace("123", "ì¼ì´ì‚¼")  # ì˜ˆì‹œ
    return text.strip()
```
---

## ğŸ“¦ 7. ë³‘ë ¬ ì „ì²˜ë¦¬ ì˜ˆì‹œ (HuggingFace datasets + map)
```python
from datasets import load_dataset

dataset = load_dataset("csv", data_files="meta.csv")

def preprocess(example):
    audio = whisper.load_audio(example["path"])
    mel = whisper.log_mel_spectrogram(audio)
    text = clean_text(example["text"])
    return {"input_features": mel, "labels": text}

dataset = dataset.map(preprocess)
```
---














