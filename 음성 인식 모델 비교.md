# 음성 인식 모델 비교: CTC VS Seq2seq

> 본 문서는 음성 인식 시스템에서 사용되는 두 가지 주요 아키텍쳐인 **CTC (Connectionist Temporal Classification)**와 **Seq2Seq (sequence-to-Sequence)*** 방식의 차이를 비교합니다.

---
## 🧩 인코더와 디코더란?

### 🟦 인코더 (Encoder)
> 입력(예: 음성)을 **숫자 벡터로 요약**해주는 역할

- 사람의 말을 컴퓨터가 이해할 수 있도록 **특징(feature)**으로 압축
- 예: `"안녕하세요"`라는 소리를 -> 숫자의 흐름으로 바꿈
- 구조 : CNN, RNN, Transformer 등이 사용됨

📦 비유: 인코더는 책의 내용을 간추려 "요약 정리"해주는 역할

---

### 🟨 디코더 (Decoder)

> 인코더가 용약한 내용을 바탕으로 **단어 또는 문장으로 재구성**

- 한 글자씩, 또는 한 단어씩 생성함
- 앞에서 말한 내용(문맥)을 기억하며 다음 글자를 예측
- Transformer 기반 모델은 이 과정에 **어텐션(attention)**을 활용

📦 비유: 디코더는 요약한 노트르르 읽고, 원래 문장처럼 말해주는 역할

---

### 🔄 전체 예시: 음성 인식 시스템

| 단계 | 설명 |
|------|------|
| 🎙️ Input | `"버튼을 눌러주세요"` 라는 음성 입력 |
| 🧠 인코더 | 이 음성을 벡터(숫자 특성)로 압축 |
| ✍️ 디코더 | "버튼을 눌러주세요"라는 텍스트를 순차적으로 생성 |

---

## 🔷 1. CTC (Connectionist Temporal Classification)

### ✅ 개요
CTC는 음성과 텍스트 간의 길이 불일치 문제를 해결하기 위한 목적의 Loss 함수 입니다.
Decoder 없이 인코더 출력만으로 텍스트 시퀀스를 예측합니다.

### ✅ 대표 모델
- Facebook `wav2vec 2.0`
- DeepSpeech
- Jasper

### ✅ 구조

[Audio Input] → [Feature Encoder (CNN + Transformer)] → [CTC Decoder]

### ✅ 특징
- **정렬 필요 없음**: 음성과 텍스트 길이 불일치 해결
- **빠름**: 디코더 없이 예측 가능 (실시간 처리에 유리)
- **blank token 사용**: 공백이나 무발화 구간을 표현
- **한계**: 문맥 이해 능력 낮음, 긴 문장 처리에 약함

---

## 🔷 2. Seq2Seq (Sequence-to-Sequence with Attention)

### ✅ 개요
Seq2Seq는 입력 시퀀스를 인코딩한 후, 디코더가 한 토큰씩 순차적으로 출력하는 구조입니다.
문맥을 더 잘 이해할 수 있으며, Transformer 기반 구조로 진화 했습니다.

### ✅ 대표 모델
- Whisper (OpenAI)
- LAS (Listen, Attend and Spell)
- ChatGPT (음성 모델은 아니지만 Seq2Seq 기반)

### ✅ 구조

[Audio Input] → [Encoder] → [Decoder (AutoRegressive, Attention)]

### ✅ 특징
- **문맥 반영 우수**: 긴 문장, 자연어 구조 이해에 강함
- **고정된 출력 없음**: 자유롭게 문장 생성 가능
- **복잡도 높음** 디코더 존재, 추론 속도 느릴 수 있음
- **대규모 데이터에 적합**

---

### 📊 비교 표
| 항목              | CTC 방식                            | Seq2Seq 방식                      |
|-------------------|--------------------------------------|----------------------------------|
| 구조              | 인코더 + CTC 디코더                  | 인코더 + 어텐션 기반 디코더     |
| 예측 방식         | 프레임 단위 출력 + 중복 제거         | 토큰 단위 순차 출력              |
| 학습 속도         | 빠름                                 | 느림                              |
| 실시간 처리       | 유리                                 | 불리                              |
| 문맥 이해         | 약함                                 | 강함                              |
| 대표 모델         | wav2vec 2.0, DeepSpeech               | Whisper, LAS                     |

---

## ✅ 결론
- **CTC**는 빠른 처리와 간결한 구조가 필요한 경우 (예: 제한된 디바이스, 키오스크)에 적합
- **Seq2Seq**는 문맥과 긴 발화까지 정확하게 인식할 필요가 있는 경우에 유리

--- 

## 
















