# CUDAë¡œ ê°€ì†í•˜ëŠ” ìŒì„± ì²˜ë¦¬ ì‹œìŠ¤í…œ ğŸ§âš¡

## ğŸ§¾ ê°œìš”
CUDAëŠ” NVIDIA GPUì˜ ë³‘ë ¬ ì—°ì‚° ëŠ¥ë ¥ì„ í™œìš©í•˜ì—¬ **ìŒì„± ì¸ì‹(STT), ìŒì„± í•©ì„±(TTS), ìŒì„± ë¶„ë¦¬, íŠ¹ì§• ì¶”ì¶œ ë“±** ë‹¤ì–‘í•œ ìŒì„± ì²˜ë¦¬ ì‘ì—…ì„ **ëŒ€í­ ê°€ì†**ì‹œí‚µë‹ˆë‹¤.

---

## ğŸ” ì™œ ìŒì„± ì²˜ë¦¬ì— CUDAê°€ í•„ìš”í•œê°€?

| ì‘ì—… ì¢…ë¥˜ | ë³‘ëª© ìš”ì†Œ | CUDAë¡œ ê°œì„ ë˜ëŠ” ì  |
|-----------|-----------|--------------------|
| ìŒì„± ì¸ì‹ (ASR) | ë”¥ëŸ¬ë‹ ëª¨ë¸ ì¶”ë¡  (RNN, Transformer ë“±) | ë³‘ë ¬ ì—°ì‚°ìœ¼ë¡œ ëª¨ë¸ ì¶”ë¡  ì†ë„ í–¥ìƒ |
| ìŒì„± í•©ì„± (TTS) | ë©œìŠ¤í™íŠ¸ë¡œê·¸ë¨ â†’ ìŒì„± ë³€í™˜ | FastSpeech, HiFi-GAN ë“± GPUë¡œ ë¹ ë¥´ê²Œ ì²˜ë¦¬ |
| íŠ¹ì§• ì¶”ì¶œ (Feature Extraction) | MFCC, Mel Filter Bank ê³„ì‚° | NumPy ëŒ€ë¹„ ìˆ˜ì‹­ ë°° ë¹ ë¥¸ ì²˜ë¦¬ |
| ì‹¤ì‹œê°„ ì²˜ë¦¬ | ì§§ì€ ì‹œê°„ ë‚´ ì²˜ë¦¬ í•„ìš” | GPU ê°€ì†ìœ¼ë¡œ latency ê°ì†Œ |

---

## âš™ï¸ CUDA ì‚¬ìš© í™˜ê²½ ì„¤ì •

### 1. CUDA Toolkit ì„¤ì¹˜
- [NVIDIA CUDA ë‹¤ìš´ë¡œë“œ](https://developer.nvidia.com/cuda-downloads)
- Pythonì—ì„œ PyTorch ë˜ëŠ” TensorFlow ì„¤ì¹˜ ì‹œ ìë™ìœ¼ë¡œ GPU ì§€ì› í¬í•¨ ê°€ëŠ¥

### 2. ë“œë¼ì´ë²„ ë° ë¼ì´ë¸ŒëŸ¬ë¦¬
- NVIDIA ë“œë¼ì´ë²„ + cuDNN ì„¤ì¹˜ ê¶Œì¥
- `nvidia-smi`ë¡œ GPU ì¸ì‹ ì—¬ë¶€ í™•ì¸

---

## ğŸ“¦ ë”¥ëŸ¬ë‹ ê¸°ë°˜ ìŒì„± ì²˜ë¦¬ì—ì„œ CUDA ì‚¬ìš© ì˜ˆ

### PyTorch ê¸°ë°˜ ìŒì„± ì¸ì‹ ì˜ˆì‹œ (Whisper)

```python
import torch
from transformers import WhisperProcessor, WhisperForConditionalGeneration

# GPUì—ì„œ ëª¨ë¸ ì‹¤í–‰
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

model = WhisperForConditionalGeneration.from_pretrained("openai/whisper-small").to(device)
processor = WhisperProcessor.from_pretrained("openai/whisper-small")

# ì˜¤ë””ì˜¤ ì…ë ¥ ì „ì²˜ë¦¬ ë° ì¸í¼ëŸ°ìŠ¤
input_features = processor(audio, return_tensors="pt").input_features.to(device)
predicted_ids = model.generate(input_features)

